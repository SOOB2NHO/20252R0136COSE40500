#!/usr/bin/env python3
# analyze_query_query_similarity.py
# 
# Original queryì™€ LLM queryë“¤ì˜ ìœ ì‚¬ë„ ë¹„êµ ë¶„ì„
# - ê° í…Œì´ë¸”(original query)ì— ëŒ€í•´:
#   1. ê°™ì€ í…Œì´ë¸”ì˜ LLM queryë“¤(ì •ë‹µ)ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
#   2. ì •ë‹µ LLM queryë“¤ ì¤‘ ìµœëŒ€ ìœ ì‚¬ë„(max)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©
#   3. ë‹¤ë¥¸ í…Œì´ë¸”ì˜ LLM queryë“¤(ë¹„ì •ë‹µ)ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
#   4. ë¹„ì •ë‹µ LLM queryë“¤ ì¤‘ ìµœëŒ€ ìœ ì‚¬ë„(max)ë¥¼ í†µê³„ ë¹„êµì— ì‚¬ìš©
#   5. ì •ë‹µì˜ ìµœëŒ€ ìœ ì‚¬ë„ë³´ë‹¤ ë†’ì€ ë¹„ì •ë‹µ ì¿¼ë¦¬ ê°œìˆ˜ ê³„ì‚°
# - ëª©ì : LLMì´ ìƒì„±í•œ queryê°€ original queryì™€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€, 
#         ê·¸ë¦¬ê³  retrievalì—ì„œ í˜¼ë™ë  ê°€ëŠ¥ì„±ì´ ìˆëŠ”ì§€ ë¶„ì„

import os
import json
import numpy as np
from typing import List, Dict, Any
import torch
import random
from pathlib import Path
import sys

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
if "CUDA_VISIBLE_DEVICES" not in os.environ:
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
torch.cuda.empty_cache()

# SACU model ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "model"))
from encoder import SacuTableEncoder


def load_qa_subset(file_path: str) -> List[Dict]:
    """QA subset íŒŒì¼ ë¡œë”© (LLMì´ ìƒì„±í•œ queryë“¤)
    
    Args:
        file_path: dev_QA_subset.jsonl íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ê° í•­ëª©ì€ {"feta_id", "query"}ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        ê° í…Œì´ë¸”ë‹¹ ì•½ 5ê°œì˜ LLM ìƒì„± queryê°€ ìˆìŒ
    """
    items = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            data = json.loads(line)
            items.append({
                "feta_id": data["feta_id"],
                "query": data["input"]["question"],
            })
    
    return items


def load_original_dev(file_path: str) -> List[Dict]:
    """Original dev íŒŒì¼ ë¡œë”© (ì›ë³¸ query)
    
    Args:
        file_path: SACU_dev.jsonl íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ê° í•­ëª©ì€ {"feta_id", "query"}ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        ì´ queryë“¤ì´ í‰ê°€ ê¸°ì¤€ì´ ë¨
    """
    items = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            data = json.loads(line)
            items.append({
                "feta_id": data["feta_id"],
                "query": data["input"]["question"],
            })
    
    return items


def analyze_query_query_similarity(
    eval_queries: List[str],
    eval_feta_ids: List[int],
    qa_items: List[Dict],
    encoder: SacuTableEncoder,
    num_samples: int = None
):
    """Original queryì™€ LLM queryë“¤ì˜ ìœ ì‚¬ë„ ë¹„êµ ë¶„ì„
    
    ê° original queryì— ëŒ€í•´:
    - ì •ë‹µ: ê°™ì€ feta_idë¥¼ ê°€ì§„ LLM queryë“¤ (ê° í…Œì´ë¸”ë‹¹ ì•½ 5ê°œ)
    - ë¹„ì •ë‹µ: ë‹¤ë¥¸ feta_idë¥¼ ê°€ì§„ LLM queryë“¤
    
    Args:
        eval_queries: í‰ê°€ ê¸°ì¤€ì´ ë˜ëŠ” original query ë¦¬ìŠ¤íŠ¸
        eval_feta_ids: ê° queryì— ëŒ€ì‘í•˜ëŠ” í…Œì´ë¸” ID ë¦¬ìŠ¤íŠ¸
        qa_items: LLMì´ ìƒì„±í•œ query ë¦¬ìŠ¤íŠ¸ (ê° í•­ëª©ì€ feta_id í¬í•¨)
        encoder: ì„ë² ë”©ì„ ìƒì„±í•  encoder
        num_samples: ë¶„ì„í•  ìƒ˜í”Œ ìˆ˜ (Noneì´ë©´ ì „ì²´)
        
    Returns:
        results ë”•ì…”ë„ˆë¦¬:
            - correct_query_similarities: ì •ë‹µ LLM queryë“¤ê³¼ì˜ ìœ ì‚¬ë„ ë¦¬ìŠ¤íŠ¸
            - incorrect_query_similarities: ë¹„ì •ë‹µ LLM queryë“¤ê³¼ì˜ ìµœëŒ€ ìœ ì‚¬ë„ ë¦¬ìŠ¤íŠ¸
            - differences: ì •ë‹µ-ë¹„ì •ë‹µ ìœ ì‚¬ë„ ì°¨ì´ ë¦¬ìŠ¤íŠ¸
            - higher_incorrect_counts: ê° í…Œì´ë¸”ë‹¹ ì •ë‹µë³´ë‹¤ ë†’ì€ ë¹„ì •ë‹µ ì¿¼ë¦¬ ê°œìˆ˜
    """
    
    results = {
        # ê° í…Œì´ë¸”ë‹¹ ì •ë‹µ LLM queryë“¤(ì•½ 5ê°œ)ì˜ ìµœëŒ€/í‰ê·  ìœ ì‚¬ë„
        "correct_max_similarities": [],  # ê° í…Œì´ë¸”ì˜ ì •ë‹µ LLM query ìµœëŒ€ ìœ ì‚¬ë„
        "correct_avg_similarities": [],  # ê° í…Œì´ë¸”ì˜ ì •ë‹µ LLM query í‰ê·  ìœ ì‚¬ë„
        # ê° í…Œì´ë¸”ë‹¹ ë¹„ì •ë‹µ LLM queryë“¤(ë‹¤ë¥¸ í…Œì´ë¸”ì˜ ëª¨ë“  query)ì˜ ìµœëŒ€/í‰ê·  ìœ ì‚¬ë„
        "incorrect_max_similarities": [],  # ê° í…Œì´ë¸”ì˜ ë¹„ì •ë‹µ LLM query ìµœëŒ€ ìœ ì‚¬ë„
        "incorrect_avg_similarities": [],  # ê° í…Œì´ë¸”ì˜ ë¹„ì •ë‹µ LLM query í‰ê·  ìœ ì‚¬ë„
        # ê° í…Œì´ë¸”ì˜ ì •ë‹µ-ë¹„ì •ë‹µ ì°¨ì´
        "max_differences": [],  # ê° í…Œì´ë¸”ì˜ ìµœëŒ€ ìœ ì‚¬ë„ ì°¨ì´ (correct_max - incorrect_max)
        "avg_differences": [],  # ê° í…Œì´ë¸”ì˜ í‰ê·  ìœ ì‚¬ë„ ì°¨ì´ (correct_avg - incorrect_avg)
        # ê° í…Œì´ë¸”ì—ì„œ ì •ë‹µë³´ë‹¤ ë†’ì€ ë¹„ì •ë‹µ ì¿¼ë¦¬ ê°œìˆ˜
        "higher_incorrect_counts_max": [],  # ì •ë‹µ maxë³´ë‹¤ ë†’ì€ ë¹„ì •ë‹µ ì¿¼ë¦¬ ê°œìˆ˜ (í…Œì´ë¸”ë‹¹)
        "higher_incorrect_counts_avg": [],  # ì •ë‹µ avgë³´ë‹¤ ë†’ì€ ë¹„ì •ë‹µ ì¿¼ë¦¬ ê°œìˆ˜ (í…Œì´ë¸”ë‹¹)
        "num_tables": 0,  # ë¶„ì„í•œ í…Œì´ë¸” ìˆ˜ (ë§ˆì§€ë§‰ì— ì´ í…Œì´ë¸”ë“¤ì˜ í‰ê· ì„ ê³„ì‚°)
    }
    
    if num_samples is None:
        num_samples = len(eval_queries)
    else:
        num_samples = min(num_samples, len(eval_queries))
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Original query vs LLM query ìœ ì‚¬ë„ ë¹„êµ ({num_samples}ê°œ ìƒ˜í”Œ)")
    print(f"   - ì •ë‹µ: ê°™ì€ í…Œì´ë¸”ì˜ LLM queryë“¤")
    print(f"   - ë¹„ì •ë‹µ: ë‹¤ë¥¸ í…Œì´ë¸”ì˜ LLM queryë“¤")
    print(f"{'='*60}\n", flush=True)
    
    # í‰ê°€ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (original devì˜ queryë“¤)
    print(f"ğŸ”„ Original query ì„ë² ë”© ìƒì„± ì¤‘... ({num_samples}ê°œ)")
    eval_query_embeddings = encoder.model.encode(
        eval_queries[:num_samples],
        convert_to_tensor=False,
        normalize_embeddings=True,
        show_progress_bar=True,
        batch_size=32
    )
    
    # QA subsetì˜ ëª¨ë“  LLM query ì„ë² ë”© ìƒì„±
    print(f"\nğŸ”„ LLM query ì„ë² ë”© ìƒì„± ì¤‘... ({len(qa_items)}ê°œ)")
    qa_queries = [item["query"] for item in qa_items]
    qa_feta_ids = [item["feta_id"] for item in qa_items]
    qa_query_embeddings = encoder.model.encode(
        qa_queries,
        convert_to_tensor=False,
        normalize_embeddings=True,
        show_progress_bar=True,
        batch_size=32
    )
    
    print(f"\nğŸ”„ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...")
    
    # ê° original queryì— ëŒ€í•´ ë¶„ì„
    for idx in range(num_samples):
        eval_query_emb = eval_query_embeddings[idx]  # í˜„ì¬ original queryì˜ ì„ë² ë”©
        eval_feta_id = eval_feta_ids[idx]  # í˜„ì¬ í…Œì´ë¸” ID
        
        # Step 1: ì •ë‹µ LLM query ì°¾ê¸°
        # ê°™ì€ feta_idë¥¼ ê°€ì§„ LLM queryë“¤ (ê° í…Œì´ë¸”ë‹¹ ì•½ 5ê°œ)
        correct_query_embs = []
        for qa_idx, qa_feta_id in enumerate(qa_feta_ids):
            if qa_feta_id == eval_feta_id:
                correct_query_embs.append(qa_query_embeddings[qa_idx])
        
        if not correct_query_embs:
            # ì •ë‹µ LLM queryê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
            continue
        
        # Step 2: ì •ë‹µ LLM queryë“¤ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        correct_sims = [np.dot(eval_query_emb, correct_emb) for correct_emb in correct_query_embs]
        max_correct_sim = max(correct_sims)  # ì •ë‹µ ì¤‘ ìµœëŒ€ ìœ ì‚¬ë„
        avg_correct_sim = np.mean(correct_sims)  # ì •ë‹µ í‰ê·  ìœ ì‚¬ë„
        
        # Step 3: ë¹„ì •ë‹µ LLM query ì°¾ê¸°
        # ë‹¤ë¥¸ feta_idë¥¼ ê°€ì§„ LLM queryë“¤ (ë‹¤ë¥¸ í…Œì´ë¸”ì˜ queryë“¤)
        incorrect_query_embs = []
        for qa_idx, qa_feta_id in enumerate(qa_feta_ids):
            if qa_feta_id != eval_feta_id:
                incorrect_query_embs.append(qa_query_embeddings[qa_idx])
        
        if not incorrect_query_embs:
            continue
        
        # Step 4: ë¹„ì •ë‹µ LLM queryë“¤ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        incorrect_sims = [np.dot(eval_query_emb, incorrect_emb) for incorrect_emb in incorrect_query_embs]
        max_incorrect_sim = max(incorrect_sims)  # ë¹„ì •ë‹µ ì¤‘ ìµœëŒ€ ìœ ì‚¬ë„
        avg_incorrect_sim = np.mean(incorrect_sims)  # ë¹„ì •ë‹µ í‰ê·  ìœ ì‚¬ë„
        
        # Step 5: ì •ë‹µë³´ë‹¤ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¹„ì •ë‹µ ì¿¼ë¦¬ ê°œìˆ˜ ê³„ì‚°
        # ì •ë‹µì˜ ìµœëŒ€/í‰ê·  ìœ ì‚¬ë„ë³´ë‹¤ ë†’ì€ ë¹„ì •ë‹µ ì¿¼ë¦¬ê°€ ëª‡ ê°œë‚˜ ìˆëŠ”ì§€ ê³„ì‚°
        higher_incorrect_count_max = sum(1 for sim in incorrect_sims if sim > max_correct_sim)
        higher_incorrect_count_avg = sum(1 for sim in incorrect_sims if sim > avg_correct_sim)
        
        # Step 6: ê²°ê³¼ ì €ì¥
        results["correct_max_similarities"].append(max_correct_sim)
        results["correct_avg_similarities"].append(avg_correct_sim)
        results["incorrect_max_similarities"].append(max_incorrect_sim)
        results["incorrect_avg_similarities"].append(avg_incorrect_sim)
        results["max_differences"].append(max_correct_sim - max_incorrect_sim)
        results["avg_differences"].append(avg_correct_sim - avg_incorrect_sim)
        results["higher_incorrect_counts_max"].append(higher_incorrect_count_max)
        results["higher_incorrect_counts_avg"].append(higher_incorrect_count_avg)
        results["num_tables"] += 1
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥
        if (idx + 1) % 100 == 0:
            print(f"   ì§„í–‰: {idx + 1}/{num_samples} ì™„ë£Œ")
    
    return results


def print_statistics(results: Dict):
    """ë¶„ì„ ê²°ê³¼ í†µê³„ ì¶œë ¥
    
    ì¶œë ¥ ë‚´ìš©:
    - ì •ë‹µ/ë¹„ì •ë‹µ LLM queryì˜ ìµœëŒ€/í‰ê·  ìœ ì‚¬ë„ ë° ë¶„í¬
    - ì •ë‹µì´ ë¹„ì •ë‹µë³´ë‹¤ ë†’ì€ ë¹„ìœ¨ (max, avg ê°ê°)
    - ê° í…Œì´ë¸”ë‹¹ ì •ë‹µë³´ë‹¤ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¹„ì •ë‹µ ì¿¼ë¦¬ ê°œìˆ˜ (max/avg ê¸°ì¤€)
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“ˆ Original query vs LLM query ìœ ì‚¬ë„ ë¹„êµ ê²°ê³¼")
    print(f"{'='*60}\n")
    
    if results["num_tables"] == 0:
        print("âŒ ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    num_tables = results["num_tables"]
    correct_max = np.array(results["correct_max_similarities"])
    correct_avg = np.array(results["correct_avg_similarities"])
    incorrect_max = np.array(results["incorrect_max_similarities"])
    incorrect_avg = np.array(results["incorrect_avg_similarities"])
    max_diffs = np.array(results["max_differences"])
    avg_diffs = np.array(results["avg_differences"])
    
    # ìµœëŒ€ ìœ ì‚¬ë„ í†µê³„
    # ê° í…Œì´ë¸”ì˜ ì •ë‹µ LLM query ìµœëŒ€ ìœ ì‚¬ë„ë“¤ì˜ í‰ê· 
    print(f"ğŸ”¹ ì •ë‹µ LLM query ìµœëŒ€ ìœ ì‚¬ë„:")
    print(f"   í…Œì´ë¸”ë‹¹ í‰ê· : {np.mean(correct_max):.4f} (ëª¨ë“  í…Œì´ë¸”ì˜ ì •ë‹µ max í‰ê· )")
    print(f"   (í‘œì¤€í¸ì°¨: {np.std(correct_max):.4f})")
    print(f"   (ìµœì†Œê°’: {np.min(correct_max):.4f}, ìµœëŒ€ê°’: {np.max(correct_max):.4f})")
    print()
    
    # ê° í…Œì´ë¸”ì˜ ë¹„ì •ë‹µ LLM query ìµœëŒ€ ìœ ì‚¬ë„ë“¤ì˜ í‰ê· 
    print(f"ğŸ”¹ ë¹„ì •ë‹µ LLM query ìµœëŒ€ ìœ ì‚¬ë„:")
    print(f"   í…Œì´ë¸”ë‹¹ í‰ê· : {np.mean(incorrect_max):.4f} (ëª¨ë“  í…Œì´ë¸”ì˜ ë¹„ì •ë‹µ max í‰ê· )")
    print(f"   (í‘œì¤€í¸ì°¨: {np.std(incorrect_max):.4f})")
    print(f"   (ìµœì†Œê°’: {np.min(incorrect_max):.4f}, ìµœëŒ€ê°’: {np.max(incorrect_max):.4f})")
    print()
    
    avg_max_diff = np.mean(max_diffs)
    print(f"ğŸ“Š ìµœëŒ€ ìœ ì‚¬ë„ ì°¨ì´:")
    print(f"   ì •ë‹µ_max - ë¹„ì •ë‹µ_max: {avg_max_diff:+.4f}")
    if avg_max_diff > 0:
        print(f"   â†’ ì •ë‹µ ìµœëŒ€ ìœ ì‚¬ë„ê°€ {avg_max_diff:.4f} ë” ë†’ìŒ")
    else:
        print(f"   â†’ ë¹„ì •ë‹µ ìµœëŒ€ ìœ ì‚¬ë„ê°€ {abs(avg_max_diff):.4f} ë” ë†’ìŒ")
    
    correct_higher_max = (max_diffs > 0).sum()
    correct_higher_max_pct = correct_higher_max / num_tables * 100
    print(f"   ì •ë‹µì´ ë” ë†’ì€ í…Œì´ë¸”: {correct_higher_max}/{num_tables} ({correct_higher_max_pct:.1f}%)")
    print()
    
    # í‰ê·  ìœ ì‚¬ë„ í†µê³„
    # ê° í…Œì´ë¸”ì˜ ì •ë‹µ LLM query í‰ê·  ìœ ì‚¬ë„ë“¤ì˜ í‰ê· 
    print(f"ğŸ”¹ ì •ë‹µ LLM query í‰ê·  ìœ ì‚¬ë„:")
    print(f"   í…Œì´ë¸”ë‹¹ í‰ê· : {np.mean(correct_avg):.4f} (ëª¨ë“  í…Œì´ë¸”ì˜ ì •ë‹µ avg í‰ê· )")
    print(f"   (í‘œì¤€í¸ì°¨: {np.std(correct_avg):.4f})")
    print(f"   (ìµœì†Œê°’: {np.min(correct_avg):.4f}, ìµœëŒ€ê°’: {np.max(correct_avg):.4f})")
    print()
    
    # ê° í…Œì´ë¸”ì˜ ë¹„ì •ë‹µ LLM query í‰ê·  ìœ ì‚¬ë„ë“¤ì˜ í‰ê· 
    print(f"ğŸ”¹ ë¹„ì •ë‹µ LLM query í‰ê·  ìœ ì‚¬ë„:")
    print(f"   í…Œì´ë¸”ë‹¹ í‰ê· : {np.mean(incorrect_avg):.4f} (ëª¨ë“  í…Œì´ë¸”ì˜ ë¹„ì •ë‹µ avg í‰ê· )")
    print(f"   (í‘œì¤€í¸ì°¨: {np.std(incorrect_avg):.4f})")
    print(f"   (ìµœì†Œê°’: {np.min(incorrect_avg):.4f}, ìµœëŒ€ê°’: {np.max(incorrect_avg):.4f})")
    print()
    
    avg_avg_diff = np.mean(avg_diffs)
    print(f"ğŸ“Š í‰ê·  ìœ ì‚¬ë„ ì°¨ì´:")
    print(f"   ì •ë‹µ_avg - ë¹„ì •ë‹µ_avg: {avg_avg_diff:+.4f}")
    if avg_avg_diff > 0:
        print(f"   â†’ ì •ë‹µ í‰ê·  ìœ ì‚¬ë„ê°€ {avg_avg_diff:.4f} ë” ë†’ìŒ")
    else:
        print(f"   â†’ ë¹„ì •ë‹µ í‰ê·  ìœ ì‚¬ë„ê°€ {abs(avg_avg_diff):.4f} ë” ë†’ìŒ")
    
    correct_higher_avg = (avg_diffs > 0).sum()
    correct_higher_avg_pct = correct_higher_avg / num_tables * 100
    print(f"   ì •ë‹µì´ ë” ë†’ì€ í…Œì´ë¸”: {correct_higher_avg}/{num_tables} ({correct_higher_avg_pct:.1f}%)")
    print()
    
    # ì •ë‹µë³´ë‹¤ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¹„ì •ë‹µ ì¿¼ë¦¬ ê°œìˆ˜ (í…Œì´ë¸”ë‹¹ í‰ê· )
    if results["higher_incorrect_counts_max"]:
        higher_counts_max = np.array(results["higher_incorrect_counts_max"])
        higher_counts_avg = np.array(results["higher_incorrect_counts_avg"])
        
        print(f"ğŸ“Š ì •ë‹µë³´ë‹¤ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¹„ì •ë‹µ ì¿¼ë¦¬ ê°œìˆ˜:")
        print(f"   (ì •ë‹µ max ê¸°ì¤€) í…Œì´ë¸”ë‹¹ í‰ê· : {np.mean(higher_counts_max):.2f}ê°œ")
        print(f"   (í‘œì¤€í¸ì°¨: {np.std(higher_counts_max):.2f})")
        print(f"   (ìµœì†Œê°’: {np.min(higher_counts_max):.0f}ê°œ, ìµœëŒ€ê°’: {np.max(higher_counts_max):.0f}ê°œ)")
        print()
        print(f"   (ì •ë‹µ avg ê¸°ì¤€) í…Œì´ë¸”ë‹¹ í‰ê· : {np.mean(higher_counts_avg):.2f}ê°œ")
        print(f"   (í‘œì¤€í¸ì°¨: {np.std(higher_counts_avg):.2f})")
        print(f"   (ìµœì†Œê°’: {np.min(higher_counts_avg):.0f}ê°œ, ìµœëŒ€ê°’: {np.max(higher_counts_avg):.0f}ê°œ)")
        print(f"   (ì´ {num_tables}ê°œ í…Œì´ë¸” ë¶„ì„)")
    
    print(f"\n{'='*60}\n")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Original query vs LLM query ìœ ì‚¬ë„ ë¶„ì„")
    parser.add_argument("--qa-file", type=str, 
                       default="/home/subeen/DaisLab/SACU/data/SACU/QA_tables/dev_QA_subset.jsonl",
                       help="QA subset íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: dev_QA_subset.jsonl)")
    parser.add_argument("--num-samples", type=int, default=None,
                       help="ë¶„ì„í•  ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ê°’: ì „ì²´)")
    
    args = parser.parse_args()
    
    print("="*60)
    print("Original query vs LLM query ìœ ì‚¬ë„ ë¶„ì„")
    print("ì •ë‹µ LLM query (ê°™ì€ í…Œì´ë¸”) vs ë¹„ì •ë‹µ LLM query (ë‹¤ë¥¸ í…Œì´ë¸”)")
    print("="*60)
    
    # Encoder ì´ˆê¸°í™”
    print("\nğŸ”§ Encoder ì´ˆê¸°í™” ì¤‘...", flush=True)
    encoder = SacuTableEncoder(
        use_stella=False,  # E5 ëª¨ë¸ ì‚¬ìš©
        use_e5=True,
        verbose=False,
        enable_query_generation=False,
        enable_column_relevance=False,
        num_rows=150,
        device="cuda"
    )
    
    # ë°ì´í„° ë¡œë”©
    data_dir = Path("/home/subeen/DaisLab/SACU/data/SACU")
    qa_subset_file = Path(args.qa_file)
    original_dev_file = data_dir / "original_tables" / "SACU_dev.jsonl"
    
    print(f"\nğŸ“ QA subset ë°ì´í„° ë¡œë”© ì¤‘: {qa_subset_file}", flush=True)
    qa_items = load_qa_subset(str(qa_subset_file))
    print(f"   âœ“ {len(qa_items)}ê°œ ìƒ˜í”Œ ë¡œë”© ì™„ë£Œ", flush=True)
    
    print(f"\nğŸ“ Original dev ë°ì´í„° ë¡œë”© ì¤‘...", flush=True)
    orig_items = load_original_dev(str(original_dev_file))
    print(f"   âœ“ {len(orig_items)}ê°œ ìƒ˜í”Œ ë¡œë”© ì™„ë£Œ", flush=True)
    
    # í‰ê°€ ì¿¼ë¦¬ëŠ” original devì˜ query ì‚¬ìš©
    eval_queries = [item["query"] for item in orig_items]
    eval_feta_ids = [item["feta_id"] for item in orig_items]
    
    # ë¶„ì„ ì‹¤í–‰
    results = analyze_query_query_similarity(
        eval_queries,
        eval_feta_ids,
        qa_items,
        encoder,
        num_samples=args.num_samples
    )
    
    # í†µê³„ ì¶œë ¥
    print_statistics(results)
    
    print("âœ… ë¶„ì„ ì™„ë£Œ!", flush=True)

